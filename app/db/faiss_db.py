import faiss
import numpy as np
from firebase_admin import firestore
from sentence_transformers import SentenceTransformer
import os
import re
import random

# âœ… Firestore ì—°ê²°
db = firestore.client()

user_profiles = {}  # âœ… ì‚¬ìš©ì ì •ë³´ ì €ì¥ {chat_id: {"ì§ì—…": "ê°œë°œì", "ì·¨ë¯¸": "ì½”ë”©"}}
character_profiles = {}  # âœ… AI ìºë¦­í„° ì •ë³´ ì €ì¥ {charac_id: {"ì·¨ë¯¸": "ì±… ì½ê¸°"}}


# âœ… ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

# âœ… FAISS ë²¡í„° DB ì´ˆê¸°í™”
dimension = 384  # SBERT ì¶œë ¥ ë²¡í„° ì°¨ì›
doc_store = {}  # âœ… ì±„íŒ…ë°©ë³„ë¡œ ë¬¸ì„œë¥¼ ì €ì¥ {chat_id: {ë¬¸ì„œ ID: í…ìŠ¤íŠ¸ ì €ì¥}}
FAISS_INDEX_DIR = "db/faiss"  # âœ… FAISS ì €ì¥ ë””ë ‰í† ë¦¬

def get_faiss_index_path(chat_id):
    """ì±„íŒ…ë°©(chat_id)ë³„ë¡œ FAISS ë²¡í„° ì €ì¥ ê²½ë¡œ ë°˜í™˜"""
    return os.path.join(FAISS_INDEX_DIR, f"faiss_index_{chat_id}.bin")

def ensure_faiss_directory():
    """FAISS ì €ì¥ ê²½ë¡œê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìƒì„±"""
    if not os.path.exists(FAISS_INDEX_DIR):
        os.makedirs(FAISS_INDEX_DIR)
        # print(f"âœ… FAISS ì €ì¥ ê²½ë¡œ ìƒì„±ë¨: {FAISS_INDEX_DIR}")

def save_faiss_index(chat_id, index):
    """ì±„íŒ…ë°©ë³„ FAISS ë²¡í„° DBë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    ensure_faiss_directory()  # âœ… ê²½ë¡œ í™•ì¸ í›„ ìƒì„±
    faiss.write_index(index, get_faiss_index_path(chat_id))
    # print(f"âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ! ({chat_id})")

def load_faiss_index(chat_id):
    """ì±„íŒ…ë°©ë³„ FAISS ë²¡í„° DBë¥¼ íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°"""
    index_path = get_faiss_index_path(chat_id)

    if os.path.exists(index_path):
        index = faiss.read_index(index_path)
        print(f"âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ! ({chat_id}) ì €ì¥ëœ ê°œìˆ˜: {index.ntotal}")

        # âœ… doc_store ë™ê¸°í™”
        if chat_id not in doc_store:
            doc_store[chat_id] = {}
        
        messages_ref = db.collection(f"chats/{chat_id}/messages").stream()
        for msg in messages_ref:
            msg_data = msg.to_dict()
            text = msg_data["content"]
            doc_id = len(doc_store[chat_id])
            doc_store[chat_id][doc_id] = text  # Firestore ë°ì´í„°ì™€ ë™ê¸°í™”
        
        return index
    else:
        return faiss.IndexFlatL2(dimension)
def load_existing_faiss_indices():
    """ì„œë²„ ì‹œì‘ ì‹œ ì €ì¥ëœ ëª¨ë“  FAISS ì¸ë±ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜´"""
    if not os.path.exists(FAISS_INDEX_DIR):
        print(f"âš ï¸ FAISS ì¸ë±ìŠ¤ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {FAISS_INDEX_DIR}")
        return

    for file in os.listdir(FAISS_INDEX_DIR):
        if file.endswith(".bin"):
            chat_id = file.replace("faiss_index_", "").replace(".bin", "")
            load_faiss_index(chat_id)
            print(f"âœ… ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {chat_id}")

def delete_faiss_index(chat_id):
    """ì±„íŒ…ë°© ì‚­ì œ ì‹œ FAISS ë²¡í„° íŒŒì¼ë„ ì‚­ì œ"""
    index_path = get_faiss_index_path(chat_id)
    
    if os.path.exists(index_path):
        os.remove(index_path)
        print(f"ğŸ—‘ï¸ FAISS ì¸ë±ìŠ¤ ì‚­ì œ ì™„ë£Œ: {index_path}")
    else:
        print(f"âš ï¸ FAISS ì¸ë±ìŠ¤ ì—†ìŒ, ì‚­ì œ ë¶ˆí•„ìš”: {index_path}")


def store_chat_in_faiss(chat_id, charac_id):
    """Firestoreì—ì„œ ì±„íŒ… ê¸°ë¡ì„ ê°€ì ¸ì™€ FAISSì— ì €ì¥ (ì‚¬ìš©ì ë° AI ì •ë³´ í¬í•¨)"""
    global user_profiles, character_profiles  # âœ… ê¸€ë¡œë²Œ ë³€ìˆ˜ ë³´ì¥

    index = faiss.IndexFlatL2(dimension)  # âœ… ìƒˆë¡œìš´ FAISS ì¸ë±ìŠ¤ ìƒì„±
    doc_store.setdefault(chat_id, {})  # âœ… ë¬¸ì¥ ì €ì¥ì†Œ ì´ˆê¸°í™”
    user_profiles.setdefault(chat_id, {})  # âœ… ì‚¬ìš©ì ì •ë³´ ê¸°ë³¸ê°’ ì„¤ì •
    character_profiles.setdefault(charac_id, {})  # âœ… ìºë¦­í„° ì •ë³´ ê¸°ë³¸ê°’ ì„¤ì •

    messages_ref = db.collection(f"chats/{chat_id}/messages").order_by("timestamp").stream()

    vectors = []  # âœ… ë²¡í„° ì €ì¥ ë¦¬ìŠ¤íŠ¸
    texts = []  # âœ… ì›ë³¸ í…ìŠ¤íŠ¸ ì €ì¥ ë¦¬ìŠ¤íŠ¸

    for msg in messages_ref:
        msg_data = msg.to_dict()
        text = msg_data["content"]

        # âœ… ì‚¬ìš©ì ì •ë³´ ì €ì¥ (íŒ¨í„´ ê¸°ë°˜ ì¶”ì¶œ)
        user_patterns = {
            "ì •ì²´ì„±": r"ë‚˜ëŠ” (.+?)(ì•¼|ì´ì•¼|í•´)",
            "ì·¨ë¯¸": r"ë‚´ ì·¨ë¯¸ëŠ” (.+?)(ì•¼|ì´ì•¼)",
            "ì§ì—…": r"ë‚´ ì§ì—…ì€ (.+?)(ì•¼|ì´ì•¼)",
            "ì‚¬ëŠ” ê³³": r"ë‚´ê°€ ì‚¬ëŠ” ê³³ì€ (.+?)(ì•¼|ì´ì•¼)",
            "ë‚˜ì´": r"ë‚˜ëŠ” (\d+)ì‚´(ì´ì•¼|ì•¼)",
            "MBTI": r"ë‚´ MBTIëŠ” (.+?)(ì•¼|ì´ì•¼)"
        }

        for key, pattern in user_patterns.items():
            match = re.search(pattern, text)  # âœ… `re.search()`ë¡œ ë¬¸ì¥ ë‚´ ì „ì²´ ê²€ìƒ‰
            if match:
                value = match.group(1).strip()
                user_profiles[chat_id][key] = value
                print(f"âœ… ì‚¬ìš©ì ì •ë³´ ì €ì¥: {key} = {value}")

        # âœ… AI ìºë¦­í„° ì •ë³´ ì €ì¥
        charac_patterns = {
            "ì„±í–¥": r"(ë„Œ|ë„ˆëŠ”) (.+?)(ì•¼|ì´ì•¼|í•˜ëŠ” ê±¸ ì¢‹ì•„í•´)"
        }
        for key, pattern in charac_patterns.items():
            match = re.search(pattern, text)
            if match:
                value = match.group(2).strip()
                character_profiles[charac_id][key] = value
                print(f"âœ… ìºë¦­í„° ì •ë³´ ì €ì¥: {key} = {value}")

        # âœ… FAISSì— ì €ì¥í•  ë¬¸ì¥ ë²¡í„°í™”
        if text not in texts:  # âœ… ì¤‘ë³µ ë°©ì§€
            texts.append(text)
            vector = model.encode([text])[0]  # âœ… ë¬¸ì¥ ë²¡í„° ìƒì„±
            vectors.append(vector)

    # âœ… FAISS ì¸ë±ìŠ¤ì— ë²¡í„° ì¶”ê°€
    if vectors:
        vectors = np.array(vectors, dtype=np.float32)
        faiss.normalize_L2(vectors)  # âœ… ë²¡í„° ì •ê·œí™”
        index.add(vectors)
        for i, text in enumerate(texts):
            doc_store[chat_id][i] = text

    # âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥
    save_faiss_index(chat_id, index)
    print(f"âœ… FAISS ì €ì¥ ì™„ë£Œ! (chat_id={chat_id}) ì €ì¥ëœ ë¬¸ì¥ ê°œìˆ˜: {index.ntotal}")

def search_similar_messages(chat_id, charac_id, query, top_k=5):
    """ì‚¬ìš©ì ë° AI ì •ë³´ ê¸°ë°˜ ê²€ìƒ‰ (ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ìŠ¤íƒ€ì¼ ì ìš©)"""

    # âœ… "ë‚´ê°€ ëˆ„êµ¬ì˜€ì§€?" ë˜ëŠ” "ë‚´ ì •ë³´" ê´€ë ¨ ì§ˆë¬¸
    if "ë‚´ê°€ ëˆ„êµ¬ì˜€ì§€" in query or "ë‚´ ì •ë³´" in query:
        if chat_id in user_profiles and user_profiles[chat_id]:
            profile_info = ", ".join([f"{k}: {v}" for k, v in user_profiles[chat_id].items()])
            responses = [
                f"ìŒ... ë‚´ê°€ ê¸°ì–µí•˜ê¸°ë¡œëŠ” {profile_info}ë¼ê³  í•˜ì…¨ë˜ ê²ƒ ê°™ì€ë°, ë§ë‚˜ìš”? ğŸ˜Š",
                f"ê¸°ì–µì„ ë”ë“¬ì–´ ë³´ë©´... {profile_info}! í˜¹ì‹œ ë” ì¶”ê°€í•  ì •ë³´ê°€ ìˆìœ¼ì‹ ê°€ìš”? ğŸ§",
                f"ë‹¹ì‹ ì— ëŒ€í•´ ê³°ê³°ì´ ìƒê°í•´ë´¤ì–´ìš”. {profile_info}ë¼ê³  í•˜ì…¨ì—ˆì£ ? ğŸ»"
            ]
            return [random.choice(responses)]
        else:
            return ["ìŒ... ì•„ì§ qqqë‹˜ì˜ ì •ë³´ë¥¼ ì˜ ëª¨ë¥´ê² ì–´ìš”! ì•Œë ¤ì£¼ì‹œë©´ ë‹¤ìŒë¶€í„° ê¸°ì–µí• ê²Œìš”! ğŸ˜Š"]

    # âœ… "ë„ˆëŠ” ëˆ„êµ¬ì•¼?" ë˜ëŠ” "ë„ˆëŠ” ë­ ì¢‹ì•„í•´?" ê´€ë ¨ ì§ˆë¬¸
    if "ë„ˆëŠ” ëˆ„êµ¬ì•¼" in query or "ë„ˆëŠ” ë­ ì¢‹ì•„í•´" in query:
        if charac_id in character_profiles and character_profiles[charac_id]:
            charac_info = ", ".join([f"{k}: {v}" for k, v in character_profiles[charac_id].items()])
            return [f"ë‚˜ëŠ” {charac_info}ë¥¼ ì¢‹ì•„í•˜ëŠ” AIì•¼! ğŸ˜Š"]
        else:
            return ["ìŒ... ì•„ì§ ì œ ì •ì²´ì„±ì— ëŒ€í•œ ì •ë³´ê°€ ë¶€ì¡±í•˜ë„¤ìš”! ì €ì— ëŒ€í•´ ì¡°ê¸ˆ ë” ì•Œë ¤ì£¼ì‹œë©´ ê¸°ì–µí•´ë³¼ê²Œìš”! ğŸ¤–"]

    # âœ… "ë‚´ê°€ ë­˜ ì¢‹ì•„í–ˆì§€?" íŒ¨í„´ ê²€ìƒ‰
    if "ë‚´ê°€ ë­˜ ì¢‹ì•„í–ˆì§€" in query or "ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” ê²ƒ" in query:
        if chat_id in user_profiles and "ì·¨ë¯¸" in user_profiles[chat_id]:
            hobby = user_profiles[chat_id]["ì·¨ë¯¸"]
            return [f"qqqë‹˜ì€ {hobby}ë¥¼ ì¢‹ì•„í•˜ì…¨ì–ì•„ìš”! ğŸ˜Š"]
        else:
            return ["ìŒ... ì•„ì§ qqqë‹˜ì˜ ì·¨í–¥ì„ ëª¨ë¥´ê² ì–´ìš”! ì¢‹ì•„í•˜ëŠ” ê±¸ ì•Œë ¤ì£¼ì‹œë©´ ë‹¤ìŒë¶€í„° ê¼­ ê¸°ì–µí• ê²Œìš”! ğŸ˜Š"]

    # âœ… ê¸°ì¡´ FAISS ê²€ìƒ‰ ìˆ˜í–‰
    index = load_faiss_index(chat_id)
    if index.ntotal == 0:
        return ["ìŒ... ì´ë²ˆ ì§ˆë¬¸ì€ ì²˜ìŒ ë“£ëŠ” ê²ƒ ê°™ì•„ìš”! ì¡°ê¸ˆ ë” ì„¤ëª…í•´ ì£¼ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”! ğŸ˜Š"]

    query_vector = model.encode([query])[0]
    query_vector = np.array([query_vector], dtype=np.float32)
    faiss.normalize_L2(query_vector)

    scores, indices = index.search(query_vector, min(top_k, index.ntotal))

    seen_texts = set()
    results = []

    for score, idx in zip(scores[0], indices[0]):
        if idx in doc_store.get(chat_id, {}):
            text = doc_store[chat_id][idx]
            if text not in seen_texts:
                results.append((text, 1 - score))
                seen_texts.add(text)

    prioritized_results = sorted(results, key=lambda x: x[1], reverse=True)

    if prioritized_results:
        similar_texts = [text for text, _ in prioritized_results[:top_k]]
        return [f"ìŒ... ë¹„ìŠ·í•œ ëŒ€í™”ë¥¼ ì°¾ì•„ë³´ë‹ˆ '{similar_texts[0]}'ë¼ê³  ë§ì”€í•˜ì‹  ì ì´ ìˆì–´ìš”! ğŸ˜Š"]

    return ["ìŒ... ì´ë²ˆ ì§ˆë¬¸ì€ ì²˜ìŒ ë“£ëŠ” ê²ƒ ê°™ì•„ìš”! ì¡°ê¸ˆ ë” ì„¤ëª…í•´ ì£¼ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”! ğŸ˜Š"]

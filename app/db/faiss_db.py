import faiss
import numpy as np
from firebase_admin import firestore
from sentence_transformers import SentenceTransformer
import os
import re
import random

# âœ… Firestore ì—°ê²°
db = firestore.client()

user_profiles = {}  # âœ… ì‚¬ìš©ì ì •ë³´ ì €ì¥ {chat_id: {"ì§ì—…": "ê°œë°œì", "ì·¨ë¯¸": "ì½”ë”©"}}
character_profiles = {}  # âœ… AI ìºë¦­í„° ì •ë³´ ì €ì¥ {charac_id: {"ì·¨ë¯¸": "ì±… ì½ê¸°"}}


# âœ… ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
model = SentenceTransformer("sentence-transformers/all-mpnet-base-v2")


# âœ… FAISS ë²¡í„° DB ì´ˆê¸°í™”
dimension = 768
doc_store = {}  # âœ… ì±„íŒ…ë°©ë³„ë¡œ ë¬¸ì„œë¥¼ ì €ì¥ {chat_id: {ë¬¸ì„œ ID: í…ìŠ¤íŠ¸ ì €ì¥}}
FAISS_INDEX_DIR = "db/faiss"  # âœ… FAISS ì €ì¥ ë””ë ‰í† ë¦¬

def get_faiss_index_path(chat_id):
    """ì±„íŒ…ë°©(chat_id)ë³„ë¡œ FAISS ë²¡í„° ì €ì¥ ê²½ë¡œ ë°˜í™˜"""
    return os.path.join(FAISS_INDEX_DIR, f"faiss_index_{chat_id}.bin")

def ensure_faiss_directory():
    """FAISS ì €ì¥ ê²½ë¡œê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìƒì„±"""
    if not os.path.exists(FAISS_INDEX_DIR):
        os.makedirs(FAISS_INDEX_DIR)
        # print(f"âœ… FAISS ì €ì¥ ê²½ë¡œ ìƒì„±ë¨: {FAISS_INDEX_DIR}")

def save_faiss_index(chat_id, index):
    """ì±„íŒ…ë°©ë³„ FAISS ë²¡í„° DBë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    ensure_faiss_directory()  # âœ… ê²½ë¡œ í™•ì¸ í›„ ìƒì„±
    faiss.write_index(index, get_faiss_index_path(chat_id))
    # print(f"âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ! ({chat_id})")

def load_faiss_index(chat_id):
    """ì±„íŒ…ë°©ë³„ FAISS ë²¡í„° DBë¥¼ íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°"""
    index_path = get_faiss_index_path(chat_id)

    if os.path.exists(index_path):
        index = faiss.read_index(index_path)
        # print(f"âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ! ({chat_id}) ì €ì¥ëœ ê°œìˆ˜: {index.ntotal}")

        # âœ… doc_store ë™ê¸°í™”
        if chat_id not in doc_store:
            doc_store[chat_id] = {}
        
        messages_ref = db.collection(f"chats/{chat_id}/messages").stream()
        for msg in messages_ref:
            msg_data = msg.to_dict()
            text = msg_data["content"]
            doc_id = len(doc_store[chat_id])
            doc_store[chat_id][doc_id] = text  # Firestore ë°ì´í„°ì™€ ë™ê¸°í™”
        
        return index
    else:
        return faiss.IndexFlatL2(dimension)
    
def load_existing_faiss_indices():
    """ì„œë²„ ì‹œì‘ ì‹œ ì €ì¥ëœ ëª¨ë“  FAISS ì¸ë±ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜´"""
    if not os.path.exists(FAISS_INDEX_DIR):
        print(f"âš ï¸ FAISS ì¸ë±ìŠ¤ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {FAISS_INDEX_DIR}")
        return

    for file in os.listdir(FAISS_INDEX_DIR):
        if file.endswith(".bin"):
            chat_id = file.replace("faiss_index_", "").replace(".bin", "")
            load_faiss_index(chat_id)
            print(f"âœ… ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {chat_id}")

def delete_faiss_index(chat_id):
    """ì±„íŒ…ë°© ì‚­ì œ ì‹œ FAISS ë²¡í„° íŒŒì¼ë„ ì‚­ì œ"""
    index_path = get_faiss_index_path(chat_id)
    
    if os.path.exists(index_path):
        os.remove(index_path)
        print(f"ğŸ—‘ï¸ FAISS ì¸ë±ìŠ¤ ì‚­ì œ ì™„ë£Œ: {index_path}")
    else:
        print(f"âš ï¸ FAISS ì¸ë±ìŠ¤ ì—†ìŒ, ì‚­ì œ ë¶ˆí•„ìš”: {index_path}")


def store_chat_in_faiss(chat_id, charac_id):
    """Firestoreì—ì„œ ì±„íŒ… ê¸°ë¡ì„ ê°€ì ¸ì™€ FAISSì— ì €ì¥ (ì‚¬ìš©ì ë° AI ì •ë³´ í¬í•¨)"""
    global user_profiles, character_profiles  # âœ… ê¸€ë¡œë²Œ ë³€ìˆ˜ ë³´ì¥

    index = faiss.IndexFlatL2(dimension)  # âœ… ìƒˆë¡œìš´ FAISS ì¸ë±ìŠ¤ ìƒì„±
    doc_store.setdefault(chat_id, {})  # âœ… ë¬¸ì¥ ì €ì¥ì†Œ ì´ˆê¸°í™”
    user_profiles.setdefault(chat_id, {})  # âœ… ì‚¬ìš©ì ì •ë³´ ê¸°ë³¸ê°’ ì„¤ì •
    character_profiles.setdefault(charac_id, {})  # âœ… ìºë¦­í„° ì •ë³´ ê¸°ë³¸ê°’ ì„¤ì •

    messages_ref = db.collection(f"chats/{chat_id}/messages").order_by("timestamp").stream()

    vectors = []  # âœ… ë²¡í„° ì €ì¥ ë¦¬ìŠ¤íŠ¸
    texts = []  # âœ… ì›ë³¸ í…ìŠ¤íŠ¸ ì €ì¥ ë¦¬ìŠ¤íŠ¸

    for msg in messages_ref:
        msg_data = msg.to_dict()
        text = msg_data["content"]

        # âœ… ì‚¬ìš©ì ì •ë³´ ì €ì¥ (íŒ¨í„´ ê¸°ë°˜ ì¶”ì¶œ)
        user_patterns = {
            "ì •ì²´ì„±": r"ë‚˜ëŠ” (.+?)(ì•¼|ì´ì•¼|í•´)",
            "ì·¨ë¯¸": r"ë‚´ ì·¨ë¯¸ëŠ” (.+?)(ì•¼|ì´ì•¼)",
            "ì§ì—…": r"ë‚´ ì§ì—…ì€ (.+?)(ì•¼|ì´ì•¼)",
            "ì‚¬ëŠ” ê³³": r"ë‚´ê°€ ì‚¬ëŠ” ê³³ì€ (.+?)(ì•¼|ì´ì•¼)",
            "ë‚˜ì´": r"ë‚˜ëŠ” (\d+)ì‚´(ì´ì•¼|ì•¼)",
            "MBTI": r"ë‚´ MBTIëŠ” (.+?)(ì•¼|ì´ì•¼)"
        }

        for key, pattern in user_patterns.items():
            match = re.search(pattern, text)  # âœ… `re.search()`ë¡œ ë¬¸ì¥ ë‚´ ì „ì²´ ê²€ìƒ‰
            if match:
                value = match.group(1).strip()
                user_profiles[chat_id][key] = value
                # print(f"âœ… ì‚¬ìš©ì ì •ë³´ ì €ì¥: {key} = {value}")

        # âœ… AI ìºë¦­í„° ì •ë³´ ì €ì¥
        charac_patterns = {
            "ì„±í–¥": r"(ë„Œ|ë„ˆëŠ”) (.+?)(ì•¼|ì´ì•¼|í•˜ëŠ” ê±¸ ì¢‹ì•„í•´)"
        }
        for key, pattern in charac_patterns.items():
            match = re.search(pattern, text)
            if match:
                value = match.group(2).strip()
                character_profiles[charac_id][key] = value
                # print(f"âœ… ìºë¦­í„° ì •ë³´ ì €ì¥: {key} = {value}")

        # âœ… FAISSì— ì €ì¥í•  ë¬¸ì¥ ë²¡í„°í™”
        if text not in texts:  # âœ… ì¤‘ë³µ ë°©ì§€
            texts.append(text)
            vector = model.encode([text])[0]  # âœ… ë¬¸ì¥ ë²¡í„° ìƒì„±
            vectors.append(vector)

    # âœ… FAISS ì¸ë±ìŠ¤ì— ë²¡í„° ì¶”ê°€
    if vectors:
        vectors = np.array(vectors, dtype=np.float32)
        faiss.normalize_L2(vectors)  # âœ… ë²¡í„° ì •ê·œí™”
        index.add(vectors)
        for i, text in enumerate(texts):
            doc_store[chat_id][i] = text

    # âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥
    save_faiss_index(chat_id, index)
    # print(f"âœ… FAISS ì €ì¥ ì™„ë£Œ! (chat_id={chat_id}) ì €ì¥ëœ ë¬¸ì¥ ê°œìˆ˜: {index.ntotal}")

def get_recent_messages(chat_id, limit=10):
    """Firestoreì—ì„œ ìµœê·¼ nê°œì˜ ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    messages_ref = db.collection(f"chats/{chat_id}/messages").order_by("timestamp", direction=firestore.Query.DESCENDING).limit(limit)
    messages = messages_ref.stream()

    recent_messages = []
    for msg in messages:
        msg_data = msg.to_dict()
        recent_messages.append({"content": msg_data["content"], "timestamp": msg_data["timestamp"]})

    return recent_messages

def search_user_hobby(chat_id):
    """ì‚¬ìš©ìì˜ ì·¨ë¯¸ë¥¼ ìµœê·¼ ëŒ€í™”ì—ì„œ ì§ì ‘ ê²€ìƒ‰"""
    messages = get_recent_messages(chat_id, limit=10)  # ìµœê·¼ 10ê°œ ëŒ€í™” ê°€ì ¸ì˜¤ê¸°
    hobby_keywords = ["ì·¨ë¯¸", "ì¢‹ì•„í•˜ëŠ”", "ë‚´ê°€ ì¢‹ì•„í•˜ëŠ”", "ë‚˜ëŠ”", "ë‚´ ì·¨ë¯¸ëŠ”"]
    
    for msg in messages:
        content = msg["content"]
        for keyword in hobby_keywords:
            if keyword in content:
                return content.replace("ë‚´ ì·¨ë¯¸ëŠ”", "ğŸ¶ ë©ë©! ë„ˆì˜ ì·¨ë¯¸ëŠ”") + "ì•¼! ğŸš²"
    
    return None  # ì·¨ë¯¸ ì •ë³´ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜

def search_similar_messages(chat_id, charac_id, query, top_k=5):
    """FAISS ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ë©´ì„œ, 'ì·¨ë¯¸' ê´€ë ¨ ì§ˆë¬¸ì¼ ê²½ìš° ìš°ì„ ì ìœ¼ë¡œ ê¸°ì–µí•œ ì •ë³´ ë°˜í™˜"""

    # âœ… ì‚¬ìš©ìì˜ ì·¨ë¯¸ ì§ˆë¬¸ì— ëŒ€í•œ ì¦‰ì‹œ ì‘ë‹µ
    if "ë‚´ê°€ ë­˜ ì¢‹ì•„í–ˆì§€" in query or "ë‚´ ì·¨ë¯¸ê°€ ë­ì˜€ì§€" in query or "ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” ê²ƒ" in query:
        # ğŸ”¹ Firestore ë˜ëŠ” FAISSì—ì„œ ì·¨ë¯¸ ì •ë³´ë¥¼ ìš°ì„  ê²€ìƒ‰
        hobby_response = search_user_hobby(chat_id)
        if hobby_response:
            return [hobby_response]
        
        if chat_id in user_profiles and "ì·¨ë¯¸" in user_profiles[chat_id]:
            hobby = user_profiles[chat_id]["ì·¨ë¯¸"]
            return [f"ğŸ¶ ë©ë©! {hobby}ê°€ ë„ˆì˜ ì·¨ë¯¸ì˜€ì§€! ê¸°ì–µí•˜ê³  ìˆì–´! ğŸš²"]

        return ["ìŒ... ì•„ì§ ë„ˆì˜ ì·¨ë¯¸ë¥¼ ì˜ ëª¨ë¥´ê² ì–´! ì•Œë ¤ì£¼ë©´ ë‚´ê°€ ê¼­ ê¸°ì–µí• ê²Œ! ğŸ˜Š"]

    # âœ… ê¸°ì¡´ FAISS ê²€ìƒ‰ ìˆ˜í–‰ (ë³€ê²½ ì—†ìŒ)
    index = load_faiss_index(chat_id)
    if index.ntotal == 0:
        return ["ìŒ... ì´ë²ˆ ì§ˆë¬¸ì€ ì²˜ìŒ ë“£ëŠ” ê²ƒ ê°™ì•„ìš”! ì¡°ê¸ˆ ë” ì„¤ëª…í•´ ì£¼ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”! ğŸ˜Š"]

    query_vector = model.encode([query])[0]
    query_vector = np.array([query_vector], dtype=np.float32)
    faiss.normalize_L2(query_vector)

    scores, indices = index.search(query_vector, min(top_k, index.ntotal))

    seen_texts = set()
    results = []

    for score, idx in zip(scores[0], indices[0]):
        if idx in doc_store.get(chat_id, {}):
            text = doc_store[chat_id][idx]
            if text not in seen_texts:
                results.append((text, 1 - score))
                seen_texts.add(text)

    prioritized_results = sorted(results, key=lambda x: x[1], reverse=True)

    if prioritized_results:
        similar_texts = [text for text, _ in prioritized_results[:top_k]]
        return [f"ìŒ... ë¹„ìŠ·í•œ ëŒ€í™”ë¥¼ ì°¾ì•„ë³´ë‹ˆ '{similar_texts[0]}'ë¼ê³  ë§ì”€í•˜ì‹  ì ì´ ìˆì–´ìš”! ğŸ˜Š"]

    return ["ìŒ... ì´ë²ˆ ì§ˆë¬¸ì€ ì²˜ìŒ ë“£ëŠ” ê²ƒ ê°™ì•„ìš”! ì¡°ê¸ˆ ë” ì„¤ëª…í•´ ì£¼ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”! ğŸ˜Š"]
